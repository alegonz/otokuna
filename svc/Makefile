HERE:=$(shell dirname $(abspath $(lastword $(MAKEFILE_LIST))))
include $(HERE)/../Makefile

.PHONY: test
test: venv
	$(VENV)/pip install -e .
	$(VENV)/pytest tests/

~/.serverless/bin/sls:
	curl -o- -L https://slss.io/install | VERSION=2.17.0 bash

.PHONY: serverless
serverless: ~/.serverless/bin/sls

package-lock.json: plugins.in
	@for plugin_name in $$(cat plugins.in); do \
	    sls plugin install --name $${plugin_name} --stage $(STAGE); \
	done

.PHONY: plugins | serverless
plugins: package-lock.json

# Note: the relative paths in the requirements files are relative to the
#   directory from where pip is invoked.
requirements.txt: ../requirements/svc.txt $(wildcard ../libs/otokuna/*) ../libs/MANIFEST.in ../libs/setup.py
	@echo '# This is file is autogenerated by Makefile' > requirements.txt \
	&& echo '# To update run: make requirements.txt' >> requirements.txt \
	&& tail -n +7 ../requirements/svc.txt >> requirements.txt \
	&& sed -i 's/-e file:libs#egg=//' requirements.txt

wheelhouse/.done: requirements.txt
	(cd .. && $(VENV)/pip wheel -r requirements/svc.txt -w svc/wheelhouse)
	touch wheelhouse/.done

.PHONY: _sls_deps
_sls_deps: plugins requirements.txt wheelhouse/.done | serverless

ifneq (,$(filter $(MAKECMDGOALS),package deploy remove))
ifndef SERVERLESS_ORG
$(error SERVERLESS_ORG is not set)
endif
endif
STAGE?=dev
SERVERLESS_ARGS=--stage $(STAGE) --org $(SERVERLESS_ORG)

export GIT_REPO_NAME = $(shell basename "$$(git rev-parse --show-toplevel)")
export GIT_BRANCH = $(shell git rev-parse --abbrev-ref HEAD)
export GIT_COMMIT_HASH_SHORT = $(shell git rev-parse --short HEAD)
export GIT_IS_DIRTY = $(shell if [ -n "$$(git diff HEAD)" ]; then echo true; else echo false; fi)

# It is safer to clean the cache of serverless-python-requirements
# to avoid missing packaging changes to the libs.
.PHONY: _clean_sls_py_req
_clean_sls_py_req: | serverless
	sls requirements clean $(SERVERLESS_ARGS)
	sls requirements cleanCache $(SERVERLESS_ARGS)

.PHONY: _pull_model
_pull_model:
	dvc pull $(shell readlink regressor.onnx)

.PHONY: package
package: _sls_deps _pull_model _clean_sls_py_req
	sls package $(SERVERLESS_ARGS)

.PHONY: deploy
deploy: _sls_deps _pull_model _clean_sls_py_req
	sls deploy $(SERVERLESS_ARGS)

.PHONY: invoke
invoke:
	sls invoke --log --function $(FUNCTION) --path $(INPUT_JSON) $(SERVERLESS_ARGS)

.PHONY: invoke-stepf
invoke-stepf:
	sls invoke stepf --name PredictDailyMachine --path $(INPUT_JSON) $(SERVERLESS_ARGS)

.PHONY: remove
remove: | serverless
	sls remove $(SERVERLESS_ARGS)

# Run invoke for a batch of dates. This is useful to apply a function
# retroactively to the data of specific dates. It needs two files:
# INPUT_JSON_TMPL: a template of the json file with the input data
#   It must have a __DATE__ string that works as a placeholder for the
#   actual string with the date.
# DATE_FILE: a file with the batch of dates (one date per line).
# Example:
# make invoke-batch FUNCTION=predict INPUT_JSON_TMPL=predict.tmpl.json DATES_FILE=dates_to_predict.txt
#
# Note that AWS_CLIENT_TIMEOUT=600000 is set so that serverless' client
# is not closed before long-running lambdas finish.
.PHONY: invoke-batch
invoke-batch:
	while read d; do \
  	echo processing $${d}; \
  	export AWS_CLIENT_TIMEOUT=600000; \
    sls invoke \
    	--log \
	    --function $(FUNCTION) \
	    --data "$$(sed s/__DATE__/$${d}/ $(INPUT_JSON_TMPL))" \
	    $(SERVERLESS_ARGS); \
	done<$(DATES_FILE)
